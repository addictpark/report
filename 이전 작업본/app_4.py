import streamlit as st
import pandas as pd

st.title("ğŸ“Š ë³´ê³ ì„œìš© ë°ì´í„° ì¶”ì¶œ í”„ë¡œê·¸ë¨")

st.info("ìƒë‹´ ì´ë ¥ ë°ì´í„°ì—ì„œ ì•„ì´ë””ì™€ íœ´ëŒ€ì „í™”ë²ˆí˜¸ë¥¼ ì‚­ì œí•˜ê³  ì—…ë¡œë“œí•˜ì„¸ìš” : )")

uploaded_counseling = st.file_uploader("ìƒë‹´ ì´ë ¥ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="counseling")
uploaded_diagnosis = st.file_uploader("ì§„ë‹¨ ì´ë ¥ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="diagnosis")

if uploaded_counseling and uploaded_diagnosis:
    df_counseling = pd.read_excel(uploaded_counseling, sheet_name=0)
    df_counseling.columns = df_counseling.columns.str.strip()  # ğŸ’¡ì¶”ê°€ë¨: ì»¬ëŸ¼ ì´ë¦„ ê³µë°± ì œê±°

    # 2ï¸âƒ£ â— ë¯¼ê°ì •ë³´ í•„ë“œ ê²€ì‚¬
    sensitive_columns = ['ì‹ ì²­ì§ì›ì´ë¦„', 'íœ´ëŒ€í°ë²ˆí˜¸']
    sensitive_found = [col for col in sensitive_columns if col in df_counseling.columns]

    if sensitive_found:
        st.error(f"âŒ ì—…ë¡œë“œí•œ ìƒë‹´ ì´ë ¥ íŒŒì¼ì— ê°œì¸ì •ë³´ ì—´({', '.join(sensitive_found)})ì´ í¬í•¨ë˜ì–´ ìˆì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n\n"
                 f"âš ï¸ í•´ë‹¹ ì—´ì„ ì‚­ì œí•œ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()  # ì•± ì‹¤í–‰ ì¤‘ë‹¨

    df_diagnosis = pd.read_excel(uploaded_diagnosis, sheet_name=0)

    def missing_summary(df, df_name="ë°ì´í„°"):
        summary = pd.DataFrame({
            'ê²°ì¸¡ì¹˜ ìˆ˜': df.isnull().sum(),
            'ì „ì²´ í–‰ ìˆ˜': len(df),
        })
        summary['ê²°ì¸¡ë¥  (%)'] = (summary['ê²°ì¸¡ì¹˜ ìˆ˜'] / summary['ì „ì²´ í–‰ ìˆ˜'] * 100).round(1)
        summary = summary[summary['ê²°ì¸¡ì¹˜ ìˆ˜'] > 0]
        if summary.empty:
            st.success(f"âœ… '{df_name}'ì—ëŠ” ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"âš ï¸ '{df_name}'ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì—´ì´ ìˆìŠµë‹ˆë‹¤.")
            st.dataframe(summary)

    st.header("ğŸ“Œ ì „ì²´ ê²°ì¸¡ì¹˜ ìš”ì•½í‘œ")

    with st.expander("ğŸ—‚ ìƒë‹´ ì´ë ¥ ê²°ì¸¡ì¹˜ ìš”ì•½"):
        missing_summary(df_counseling, df_name="ìƒë‹´ ì´ë ¥")

    with st.expander("ğŸ—‚ ì§„ë‹¨ ì´ë ¥ ê²°ì¸¡ì¹˜ ìš”ì•½"):
        missing_summary(df_diagnosis, df_name="ì§„ë‹¨ ì´ë ¥")

    # ë‚ ì§œ/ê¸°ì´ˆ ì „ì²˜ë¦¬
    df_counseling['ìƒë‹´ì‹¤ì‹œì¼'] = pd.to_datetime(df_counseling['ìƒë‹´ì‹¤ì‹œì¼'], errors='coerce')
    df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'] = pd.to_datetime(df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'], errors='coerce')
    df_counseling['ì—°ë ¹ëŒ€'] = (df_counseling['ì‹ ì²­ì§ì›ë‚˜ì´'] // 10 * 10).astype('Int64').astype(str) + 'ëŒ€'
    df_counseling['ì„±ë³„'] = df_counseling['ì‹ ì²­ì§ì›ì„±ë³„'].fillna('ë¯¸ìƒ')
    df_counseling['ìƒë‹´ì›”'] = df_counseling['ìƒë‹´ì‹¤ì‹œì¼'].dt.to_period('M')
    df_diagnosis['ì§„ë‹¨ì›”'] = df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'].dt.to_period('M')
    df_counseling['ìƒë‹´ì›”ëª…'] = df_counseling['ìƒë‹´ì‹¤ì‹œì¼'].dt.strftime('%mì›”')
    df_diagnosis['ì§„ë‹¨ì›”ëª…'] = df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'].dt.strftime('%mì›”')

    st.header("1. ìš´ì˜ ìš”ì•½")

    monthly_summary = pd.DataFrame()
    monthly_summary['ì›”'] = sorted(set(df_counseling['ìƒë‹´ì›”ëª…'].dropna()) | set(df_diagnosis['ì§„ë‹¨ì›”ëª…'].dropna()))
    monthly_summary['ì‹¬ë¦¬ìƒë‹´'] = monthly_summary['ì›”'].apply(lambda m: df_counseling[df_counseling['ìƒë‹´ì›”ëª…'] == m]['ì•„ì´ë””'].nunique())
    monthly_summary['ì‹¬ë¦¬ì§„ë‹¨'] = monthly_summary['ì›”'].apply(lambda m: df_diagnosis[df_diagnosis['ì§„ë‹¨ì›”ëª…'] == m]['ì•„ì´ë””'].nunique())
    monthly_summary['í•©ê³„'] = monthly_summary['ì‹¬ë¦¬ìƒë‹´'] + monthly_summary['ì‹¬ë¦¬ì§„ë‹¨']

    total_counseling_ids = df_counseling['ì•„ì´ë””'].nunique()
    total_diagnosis_ids = df_diagnosis['ì•„ì´ë””'].nunique()
    total_combined_ids = pd.concat([df_counseling[['ì•„ì´ë””']], df_diagnosis[['ì•„ì´ë””']]]).drop_duplicates()['ì•„ì´ë””'].nunique()

    monthly_summary.loc[len(monthly_summary)] = ['ëˆ„ê³„', monthly_summary['ì‹¬ë¦¬ìƒë‹´'].sum(), monthly_summary['ì‹¬ë¦¬ì§„ë‹¨'].sum(), monthly_summary['í•©ê³„'].sum()]
    monthly_summary.loc[len(monthly_summary)] = ['ì‹¤ê³„', total_counseling_ids, total_diagnosis_ids, total_combined_ids]

    st.markdown("ì„œë¹„ìŠ¤ ì´ìš© ì¸ì›")
    st.dataframe(monthly_summary)

    combined_ids = pd.concat([df_counseling[['ì•„ì´ë””']], df_diagnosis[['ì•„ì´ë””']]])
    unique_ids = combined_ids['ì•„ì´ë””'].drop_duplicates()
    unique_ids = unique_ids[unique_ids.notnull() & (unique_ids != "")]
    st.write("ì‹¤ì œ ì¸ì›(ì¤‘ë³µ ì œê±°):", unique_ids.tolist())
    st.write("ì‹¤ì œ ì¸ì› ìˆ˜:", len(unique_ids))

    st.markdown("ì„œë¹„ìŠ¤ ì´ìš© íšŸìˆ˜")
    monthly_summary_count = pd.DataFrame()
    monthly_summary_count['ì›”'] = sorted(set(df_counseling['ìƒë‹´ì›”ëª…'].dropna()) | set(df_diagnosis['ì§„ë‹¨ì›”ëª…'].dropna()))
    monthly_summary_count['ì‹¬ë¦¬ìƒë‹´'] = monthly_summary_count['ì›”'].apply(lambda m: len(df_counseling[df_counseling['ìƒë‹´ì›”ëª…'] == m]))
    monthly_summary_count['ì‹¬ë¦¬ì§„ë‹¨'] = monthly_summary_count['ì›”'].apply(lambda m: len(df_diagnosis[df_diagnosis['ì§„ë‹¨ì›”ëª…'] == m]))
    monthly_summary_count['í•©ê³„'] = monthly_summary_count['ì‹¬ë¦¬ìƒë‹´'] + monthly_summary_count['ì‹¬ë¦¬ì§„ë‹¨']

    monthly_summary_count.loc[len(monthly_summary_count)] = ['ëˆ„ê³„', monthly_summary_count['ì‹¬ë¦¬ìƒë‹´'].sum(), monthly_summary_count['ì‹¬ë¦¬ì§„ë‹¨'].sum(), monthly_summary_count['í•©ê³„'].sum()]

    st.dataframe(monthly_summary_count)

    st.header("2. ìƒë‹´ í†µê³„")

    st.subheader("1) ìƒë‹´ìœ í˜•ë³„ ì¸ì› ë° íšŸìˆ˜")
    st.markdown("**ìƒë‹´ìœ í˜•ë³„ ì´ìš© ì¸ì›**")
    type_people = df_counseling.groupby(['ìƒë‹´ì›”ëª…', 'ìƒë‹´ìœ í˜•'])['ì•„ì´ë””'].nunique().reset_index()
    type_people_summary = type_people.pivot(index='ìƒë‹´ì›”ëª…', columns='ìƒë‹´ìœ í˜•', values='ì•„ì´ë””').fillna(0).astype(int)
    type_people_summary['í•©ê³„'] = type_people_summary.sum(axis=1)
    type_people_summary.loc['ëˆ„ê³„'] = type_people_summary.sum()

    real_type_people = df_counseling.groupby('ìƒë‹´ìœ í˜•')['ì•„ì´ë””'].nunique()
    ì‹¤ê³„_í–‰_people = real_type_people.reindex(type_people_summary.columns[:-1]).fillna(0).astype(int)
    ì‹¤ê³„_í•©ê³„_people = pd.Series([real_type_people.sum()], index=['í•©ê³„'])
    type_people_summary.loc['ì‹¤ê³„'] = pd.concat([ì‹¤ê³„_í–‰_people, ì‹¤ê³„_í•©ê³„_people])
    st.dataframe(type_people_summary)

    st.markdown("**ìƒë‹´ìœ í˜•ë³„ ì´ìš© íšŸìˆ˜**")
    type_counts = df_counseling.groupby(['ìƒë‹´ì›”ëª…', 'ìƒë‹´ìœ í˜•'])['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
    type_counts_summary = type_counts.pivot(index='ìƒë‹´ì›”ëª…', columns='ìƒë‹´ìœ í˜•', values='ì‚¬ë¡€ë²ˆí˜¸').fillna(0).astype(int)
    type_counts_summary['í•©ê³„'] = type_counts_summary.sum(axis=1)
    type_counts_summary.loc['ëˆ„ê³„'] = type_counts_summary.sum()
    st.dataframe(type_counts_summary)

    st.markdown("---")

    st.subheader("2) ì„±ë³„ ì´ìš© ì¸ì› ë° íšŸìˆ˜")
    st.markdown("**ì„±ë³„ ì´ìš© ì¸ì›**")
    gender_people = df_counseling.groupby(['ìƒë‹´ì›”ëª…', 'ì„±ë³„'])['ì•„ì´ë””'].nunique().reset_index()
    gender_people_summary = gender_people.pivot(index='ìƒë‹´ì›”ëª…', columns='ì„±ë³„', values='ì•„ì´ë””').fillna(0).astype(int)
    gender_people_summary['í•©ê³„'] = gender_people_summary.sum(axis=1)
    gender_people_summary.loc['ëˆ„ê³„'] = gender_people_summary.sum()

    real_gender_people = df_counseling.groupby('ì„±ë³„')['ì•„ì´ë””'].nunique()
    ì‹¤ê³„_í–‰_gender = real_gender_people.reindex(gender_people_summary.columns[:-1]).fillna(0).astype(int)
    ì‹¤ê³„_í•©ê³„_gender = pd.Series([real_gender_people.sum()], index=['í•©ê³„'])
    gender_people_summary.loc['ì‹¤ê³„'] = pd.concat([ì‹¤ê³„_í–‰_gender, ì‹¤ê³„_í•©ê³„_gender])
    st.dataframe(gender_people_summary)

    st.markdown("**ì„±ë³„ ì´ìš© íšŸìˆ˜**")
    gender_counts = df_counseling.groupby(['ìƒë‹´ì›”ëª…', 'ì„±ë³„'])['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
    gender_counts_summary = gender_counts.pivot(index='ìƒë‹´ì›”ëª…', columns='ì„±ë³„', values='ì‚¬ë¡€ë²ˆí˜¸').fillna(0).astype(int)
    gender_counts_summary['í•©ê³„'] = gender_counts_summary.sum(axis=1)
    gender_counts_summary.loc['ëˆ„ê³„'] = gender_counts_summary.sum()
    st.dataframe(gender_counts_summary)

    st.markdown("---")   

    st.subheader("3) ì—°ë ¹ë³„ ì¸ì› ë° íšŸìˆ˜")
    age_monthly = df_counseling.groupby(['ìƒë‹´ì›”', 'ì—°ë ¹ëŒ€']).agg(
        ì¸ì›ìˆ˜=('ì•„ì´ë””', 'nunique'),
        ê±´ìˆ˜=('ì‚¬ë¡€ë²ˆí˜¸', 'count')
    ).reset_index()

    age_pivot_people = age_monthly.pivot(index='ìƒë‹´ì›”', columns='ì—°ë ¹ëŒ€', values='ì¸ì›ìˆ˜').fillna(0).astype(int)
    age_pivot_people['í•©ê³„'] = age_pivot_people.sum(axis=1)

    age_pivot_cases = age_monthly.pivot(index='ìƒë‹´ì›”', columns='ì—°ë ¹ëŒ€', values='ê±´ìˆ˜').fillna(0).astype(int)
    age_pivot_cases['í•©ê³„'] = age_pivot_cases.sum(axis=1)
    age_pivot_cases.loc['í•©ê³„'] = age_pivot_cases.sum()


    age_pivot_people.loc['ëˆ„ê³„'] = age_pivot_people.sum()
    real_count = df_counseling.groupby('ì—°ë ¹ëŒ€')['ì•„ì´ë””'].nunique()
    ì‹¤ê³„_í–‰ = real_count.reindex(age_pivot_people.columns[:-1]).fillna(0).astype(int)
    ì‹¤ê³„_í•©ê³„ = pd.Series([real_count.sum()], index=['í•©ê³„'])
    age_pivot_people.loc['ì‹¤ê³„'] = pd.concat([ì‹¤ê³„_í–‰, ì‹¤ê³„_í•©ê³„])

    st.markdown("**ì—°ë ¹ë³„ ì´ìš© ì¸ì›**")
    st.dataframe(age_pivot_people)

    st.markdown("**ì—°ë ¹ë³„ ì´ìš© íšŸìˆ˜**")
    st.dataframe(age_pivot_cases)

    st.markdown("---")

    st.header("3. ì‹¬ë¦¬ì§„ë‹¨ ì´ìš© ì¸ì› ë° íšŸìˆ˜")

    st.markdown("**ì‹¬ë¦¬ì§„ë‹¨ ì´ìš© ì¸ì›**")
    diag_people = df_diagnosis.groupby(['ì§„ë‹¨ì›”', 'ì§„ë‹¨ëª…'])['ì•„ì´ë””'].nunique().reset_index()
    diag_people_summary = diag_people.pivot(index='ì§„ë‹¨ì›”', columns='ì§„ë‹¨ëª…', values='ì•„ì´ë””').fillna(0).astype(int)
    diag_people_summary['í•©ê³„'] = diag_people_summary.sum(axis=1)
    diag_people_summary.loc['ëˆ„ê³„'] = diag_people_summary.sum()

    real_diag_people = df_diagnosis.drop_duplicates(subset=['ì•„ì´ë””', 'ì§„ë‹¨ëª…']).groupby('ì§„ë‹¨ëª…')['ì•„ì´ë””'].count()
    ì‹¤ê³„_í–‰_diag = real_diag_people.reindex(diag_people_summary.columns[:-1]).fillna(0).astype(int)
    ì‹¤ê³„_í•©ê³„_diag = pd.Series([df_diagnosis['ì•„ì´ë””'].nunique()], index=['í•©ê³„'])
    diag_people_summary.loc['ì‹¤ê³„'] = pd.concat([ì‹¤ê³„_í–‰_diag, ì‹¤ê³„_í•©ê³„_diag])

    st.dataframe(diag_people_summary)

    st.markdown("**ì‹¬ë¦¬ì§„ë‹¨ ì´ìš© íšŸìˆ˜**")
    diag_counts = df_diagnosis.groupby(['ì§„ë‹¨ì›”', 'ì§„ë‹¨ëª…'])['ì‹œí–‰ë²ˆí˜¸'].count().reset_index()
    diag_counts_summary = diag_counts.pivot(index='ì§„ë‹¨ì›”', columns='ì§„ë‹¨ëª…', values='ì‹œí–‰ë²ˆí˜¸').fillna(0).astype(int)
    diag_counts_summary['í•©ê³„'] = diag_counts_summary.sum(axis=1)
    diag_counts_summary.loc['ëˆ„ê³„'] = diag_counts_summary.sum()
    st.dataframe(diag_counts_summary)

   


    # =============== ì˜ì—­(ëŒ€ë¶„ë¥˜) ìë™ ë§¤í•‘ ================
    combined_mapping_dict = {
        # ì§ì¥
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ìƒì‚¬ì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ë¶€í•˜ì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ë™ë£Œì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'íŒ€ì›Œí¬ ë° ì‚¬ê¸° ì €í•˜'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì´ì§ê³ ë¯¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¡°ì§ë¬¸í™” ë¶€ì ì‘'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì—…ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¼í•  ì˜ìš•ì˜ ìƒì‹¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§ë¬´ì¬ë°°ì¹˜(TM,ì „ê·¼,ì´ì§)'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ìŠ¹ì§„ë¬¸ì œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'êµëŒ€ê·¼ë¬´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì—´ì•…í•œ ê·¼ë¬´ì¡°ê±´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§•ê³„/ê°ë´‰/ì§ìœ„í•´ì œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ë³´ìˆ˜ì— ë¶ˆë§Œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì‚°ì¬ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì”ì—…/íŠ¹ê·¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¶œí‡´ê·¼ ê´€ë ¨'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì ì„±ì— ë§ì§€ ì•ŠëŠ” ì—…ë¬´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì„±ì°¨ë³„'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì„±í¬ë¡±'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ê°ì •ë…¸ë™'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¦ì€ ì•¼ê·¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'íœ´ì§í›„ ë³µê·€'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ë¦¬ë”ì‹­'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹œê°„ê´€ë¦¬'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì§„ë¡œ ë° ê²½ë ¥ê³„ë°œ'): 'ì§ì¥',
	('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹¤ì§ or ì •ë¦¬í•´ê³  ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
	('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹¤ì ì••ë°•'): 'ì§ì¥',
	('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì •ë…„í‡´ì§'): 'ì§ì¥',
	('ì—­ëŸ‰ ë° ê²½ë ¥', 'í‡´ì§ í›„ ì¸ìƒì„¤ê³„'): 'ì§ì¥',

        # í•™êµ
        ('í•™êµìƒí™œ', 'ì „ê³µ/ì§„ë¡œ ë¬¸ì œ'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'í•™ì—…/í•™ìŠµ ë¬¸ì œ'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'íœ´í•™ ë° ë³µí•™'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'ê²½ì œì  ë¬¸ì œ (í•™ìê¸ˆ)'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'êµìˆ˜ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'ì¹œêµ¬ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'ì„ í›„ë°°ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        # ê°€ì¡±
        ('ë¶€ë¶€', 'ë¶€ë¶€ê°ˆë“±'): 'ê°€ì¡±',
        ('ë¶€ë¶€', 'ì´í˜¼ê³ ë¯¼'): 'ê°€ì¡±',
        ('ë¶€ë¶€', 'ì‚¬ë³„'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì¡±ê°ˆë“±(ë¶€ëª¨, í˜•ì œ ë“±)'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê³ ë¶€/ì²˜ê°€ ê°ˆë“±'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ë…¸ë¶€ëª¨ ë´‰ì–‘'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì •í­ë ¥'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì¡±ì‚¬ë§(ë¶€ëª¨, í˜•ì œ ë“±)'): 'ê°€ì¡±',
        ('ìë…€', 'ê°€ì¡±ëŒë´„(ì¥ì• ë³´í˜¸, ìš”ì–‘ë³´í˜¸)'): 'ê°€ì¡±',
        ('ìë…€', 'ìë…€ì–‘ìœ¡/êµìœ¡'): 'ê°€ì¡±',
        ('ìë…€', 'ìë…€ ì •ì„œë¬¸ì œ(ìš°ìš¸, ë¶ˆì•ˆ, ADHD)'): 'ê°€ì¡±',
        ('ìë…€', 'ë°œë‹¬ì§€ì—°'): 'ê°€ì¡±',
        ('ìë…€', 'ì¥ì• ìë…€ ëŒë´„'): 'ê°€ì¡±',

        # ê°œì¸
        ('ì¼ë°˜', 'ëŒ€ì¸ê´€ê³„'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì‚¶ì˜ ì˜ë¯¸ì™€ ëª©í‘œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì„±ê²©ê³ ë¯¼'): 'ê°œì¸',
        ('ì¼ë°˜', 'ìê¸°ê³„ë°œ ë° ì„±ì¥'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì´ì„±êµì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì„±ìƒí™œë¬¸ì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ê±´ê°• ë° ì§ˆë³‘ ê´€ë ¨ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì½”ë¡œë…¸ ê´€ë ¨ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì¢…êµì /ì˜ì  ë¬¸ì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ë¹„ë§Œ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì •ì„œì†Œì§„(ë²ˆì•„ì›ƒ)'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ìš°ìš¸ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¶ˆì•ˆ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê³µí™©ì¥ì• '): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¶ˆë©´ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê°•ë°•'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì§œì¦/ë¶„ë…¸'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê°ì •ê¸°ë³µ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì¡°ìš¸ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'í™˜ê°/í™˜ì²­'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'PTSD'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ìí•´'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¬´ê¸°ë ¥'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì‚°í›„ìš°ìš¸'): 'ê°œì¸',
        ('ì¤‘ë…', 'ì¸í„°ë„·/ê²Œì„/ìŠ¤ë§ˆíŠ¸í°'): 'ê°œì¸',
	('ì¤‘ë…', 'ì•Œì½”ì˜¬'): 'ê°œì¸',
	('ì¤‘ë…', 'ë„ë°•'): 'ê°œì¸',
	('ì¤‘ë…', 'í¡ì—°'): 'ê°œì¸',
	('ìì‚´ìœ„ê¸°', 'ìì‚´ìƒê°'): 'ê°œì¸',
	('ìì‚´ìœ„ê¸°', 'ìì‚´ê³„íš'): 'ê°œì¸',
	('ìì‚´ìœ„ê¸°', 'ìì‚´ì‹œë„ê²½í—˜'): 'ê°œì¸',
	('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ë²•ë¥ ìƒë‹´(ë³€í˜¸ì‚¬)'): 'ê°œì¸',
	('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'íšŒê³„ìƒë‹´(íšŒê³„ì‚¬)'): 'ê°œì¸',
	('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ì¬ë¬´ìƒë‹´(ì¬ë¬´ì„¤ê³„ì‚¬)'): 'ê°œì¸',
	('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ì„¸ë¬´ìƒë‹´(ì„¸ë¬´ì‚¬'): 'ê°œì¸',
	('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ê±´ê°•ìƒë‹´'): 'ê°œì¸',
    }

    def clean_str(s):
        if pd.isnull(s):
            return ""
        return str(s).strip().replace(" ", "").lower()

    combined_mapping_dict_clean = {
        (clean_str(k1), clean_str(k2)): v
        for (k1, k2), v in combined_mapping_dict.items()
    }

    def map_region(row):
        if clean_str(row['ì£¼í˜¸ì†Œ1']) == 'ê¸°íƒ€':
            return 'ê¸°íƒ€'
        return combined_mapping_dict_clean.get(
            (clean_str(row['ì£¼í˜¸ì†Œ1']), clean_str(row['í•˜ìœ„ìš”ì†Œ1'])), None
        )

    df_counseling['ì˜ì—­'] = df_counseling.apply(map_region, axis=1)



    # =============== ìƒë‹´ ì£¼ì œë³„ í†µê³„ ================

    count_df = (
        df_counseling
        .groupby(['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1'])
        .size().reset_index(name='ìƒë‹´ê±´ìˆ˜')
        .sort_values(['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1'])
        .reset_index(drop=True)
    )
    st.header("4. ìƒë‹´ ì£¼ì œë³„ í†µê³„")
    st.markdown("**1) ê°œìš”**")
    st.dataframe(count_df)

    # ë§¤í•‘ ì•ˆ ëœ(ë¯¸ë¶„ë¥˜) ê±´ í™•ì¸
    not_mapped = df_counseling[df_counseling['ì˜ì—­'].isnull()]

    # ì£¼í˜¸ì†Œ1/í•˜ìœ„ìš”ì†Œ1ì´ ëª¨ë‘ ë¹„ì–´ìˆëŠ” í–‰ ì œì™¸
    not_mapped = not_mapped[~(not_mapped['ì£¼í˜¸ì†Œ1'].isnull() & not_mapped['í•˜ìœ„ìš”ì†Œ1'].isnull())]

    st.write(f"â—ï¸ë§¤í•‘ì´ ì•ˆ ëœ ìƒë‹´(ë¯¸ë¶„ë¥˜) ê±´ìˆ˜: {len(not_mapped)}")
    if len(not_mapped) > 0:
        st.write("ğŸŸ¡ ë¯¸ë¶„ë¥˜ ê±´(ì£¼í˜¸ì†Œ1, í•˜ìœ„ìš”ì†Œ1) ëª©ë¡ (ì¤‘ë³µì œê±°):")
        st.dataframe(not_mapped[['ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1']].drop_duplicates())


    # ====== ê¸°ì¡´ ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„ ======
    area_sum_df = (
        count_df.groupby('ì˜ì—­')['ìƒë‹´ê±´ìˆ˜'].sum().reset_index()
        .sort_values('ìƒë‹´ê±´ìˆ˜', ascending=False)
    )
    area_sum_df.columns = ['ì˜ì—­', 'ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„']

    # ğŸ‘‡ 'í•©ê³„' í–‰ ì¶”ê°€
    total_row = pd.DataFrame({
    'ì˜ì—­': ['í•©ê³„'],
    'ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„': [area_sum_df['ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„'].sum()]
})
    area_sum_df_with_total = pd.concat([area_sum_df, total_row], ignore_index=True)

    st.markdown("**2) ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„**")
    st.dataframe(area_sum_df_with_total)


    # ====== ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„ ======
    main_issue_sum_df = (
        count_df
        .groupby(['ì˜ì—­','ì£¼í˜¸ì†Œ1'])['ìƒë‹´ê±´ìˆ˜'].sum()
        .reset_index()
        .sort_values('ìƒë‹´ê±´ìˆ˜', ascending=False)
)

    main_issue_sum_df.columns = ['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„']
    
    st.markdown("**3) ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„**")
    st.dataframe(main_issue_sum_df)

    # ğŸ’¡ì¶”ê°€ë¨: ì£¼í˜¸ì†Œ1 ê²°ì¸¡ì¹˜ í™•ì¸
    missing_count = df_counseling['ì£¼í˜¸ì†Œ1'].isnull().sum()
    if missing_count > 0:
        st.warning(f"âš ï¸ 'ì£¼í˜¸ì†Œ1' ì—´ì— ê²°ì¸¡ì¹˜ê°€ {missing_count}ê±´ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ í–‰ì€ ë¶„ì„ì—ì„œ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        with st.expander("ğŸ” 'ì£¼í˜¸ì†Œ1' ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ìƒë‹´ ë‚´ì—­ ë³´ê¸°"):
            st.dataframe(df_counseling[df_counseling['ì£¼í˜¸ì†Œ1'].isnull()][['ì‚¬ë¡€ë²ˆí˜¸', 'ì•„ì´ë””', 'ìƒë‹´ì‹¤ì‹œì¼', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1']])
    else:
        st.info("âœ… 'ì£¼í˜¸ì†Œ1' ì—´ì— ê²°ì¸¡ì¹˜ëŠ” ì—†ìŠµë‹ˆë‹¤.")



    st.header("5. ë‚´ë‹´ìë³„ ì „ì²´ ìƒë‹´ ì´ìš© íšŸìˆ˜")

    # ì•„ì´ë””ë³„ ìƒë‹´ ê±´ìˆ˜ ì§‘ê³„
    client_counts = df_counseling.groupby('ì•„ì´ë””')['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
    client_counts.columns = ['ì•„ì´ë””', 'ìƒë‹´íšŸìˆ˜']

    # ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘í•˜ëŠ” ë²ˆí˜¸ë¡œ ì¶”ê°€
    client_counts.index = client_counts.index + 1
    client_counts.reset_index(inplace=True)
    client_counts.rename(columns={'index': 'No'}, inplace=True)

    # ğŸ’¡ í•©ê³„ í–‰ ì¶”ê°€
    total_row = pd.DataFrame([{
        'No': 'í•©ê³„',
        'ì•„ì´ë””': f"ì´ {client_counts['ì•„ì´ë””'].nunique()}ëª…",
        'ìƒë‹´íšŸìˆ˜': client_counts['ìƒë‹´íšŸìˆ˜'].sum()
}])

    client_counts_with_total = pd.concat([client_counts, total_row], ignore_index=True)

# ì¶œë ¥
    st.dataframe(client_counts_with_total)



