import streamlit as st
import pandas as pd
import numpy as np

# ---------------------- ì‚¬ì´ë“œë°” ë©”ë‰´ êµ¬ì„± ----------------------
st.sidebar.title("ğŸ“‹ ë©”ë‰´")
menu = st.sidebar.radio("ì´ë™í•  ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", [
    "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° ê²°ì¸¡ì¹˜ í™•ì¸",
    "ğŸ“Š ìš´ì˜ ìš”ì•½",
    "ğŸ“ˆ ìƒë‹´ í†µê³„",
    "ğŸ§  ì‹¬ë¦¬ì§„ë‹¨ í†µê³„",
    "ğŸ—‚ï¸ ìƒë‹´ ì£¼ì œë³„ í†µê³„"
])

# ---------------------- íŒŒì¼ ì—…ë¡œë“œ ----------------------
if menu == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° ê²°ì¸¡ì¹˜ í™•ì¸":
    st.title("ë³´ê³ ì„œìš© ë°ì´í„° ì¶”ì¶œ í”„ë¡œê·¸ë¨")
    st.markdown("---")
    st.info(
        "ì—…ë¡œë“œ ì „ ê¼­ í™•ì¸í•˜ì„¸ìš”!\n"
        "- ìƒë‹´ ì´ë ¥ ì—‘ì…€ íŒŒì¼ì—ì„œ ì•„ì´ë””ì™€ íœ´ëŒ€ì „í™”ë²ˆí˜¸ ë“± ê°œì¸ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì‚­ì œí•œ í›„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "- í•´ë‹¹ ì—´(ì»¬ëŸ¼)ì€ ë°˜ë“œì‹œ ì‚­ì œ ë˜ëŠ” ë¹„ì‹ë³„(ë¹ˆì¹¸) ì²˜ë¦¬ í›„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    st.header("íŒŒì¼ ì—…ë¡œë“œ")
    col1, col2 = st.columns(2)
    with col1:
        uploaded_counseling = st.file_uploader("ìƒë‹´ ì´ë ¥ ì—‘ì…€ íŒŒì¼", type=["xlsx"], key="counseling")
    with col2:
        uploaded_diagnosis = st.file_uploader("ì§„ë‹¨ ì´ë ¥ ì—‘ì…€ íŒŒì¼", type=["xlsx"], key="diagnosis")
    if uploaded_counseling and uploaded_diagnosis:
        st.session_state['df_counseling'] = pd.read_excel(uploaded_counseling)
        st.session_state['df_diagnosis'] = pd.read_excel(uploaded_diagnosis)
        st.success("íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë©”ë‰´ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    elif 'df_counseling' not in st.session_state or 'df_diagnosis' not in st.session_state:
        st.warning("ë‘ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

# ---------------------- ë°ì´í„° ì¤€ë¹„ ë° ë©”ë‰´ë³„ ê¸°ëŠ¥ ----------------------
if 'df_counseling' in st.session_state and 'df_diagnosis' in st.session_state:
    df_counseling = st.session_state['df_counseling']
    df_diagnosis = st.session_state['df_diagnosis']

    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±° ë° ì „ì²˜ë¦¬
    df_counseling.columns = df_counseling.columns.str.strip()
    df_diagnosis.columns = df_diagnosis.columns.str.strip()

    # ê°œì¸ì •ë³´ í•„ë“œ ì°¨ë‹¨
    sensitive_columns = ['ì‹ ì²­ì§ì›ì´ë¦„', 'íœ´ëŒ€í°ë²ˆí˜¸']
    sensitive_found = [col for col in sensitive_columns if col in df_counseling.columns]
    if sensitive_found:
        st.error(
            f"ì—…ë¡œë“œ íŒŒì¼ì— ê°œì¸ì •ë³´ ì—´({', '.join(sensitive_found)})ì´ í¬í•¨ë˜ì–´ ìˆì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n\n"
            "í•´ë‹¹ ì—´ì„ ì‚­ì œí•œ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
        )
        st.stop()

    # ë‚ ì§œ, ì—°ì›”, ì—°ë ¹ëŒ€, ì„±ë³„ ë“± ê³µí†µ ì „ì²˜ë¦¬
    df_counseling['ìƒë‹´ì‹¤ì‹œì¼'] = pd.to_datetime(df_counseling['ìƒë‹´ì‹¤ì‹œì¼'], errors='coerce')
    df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'] = pd.to_datetime(df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'], errors='coerce')
    df_counseling['ìƒë‹´ì—°ì›”'] = df_counseling['ìƒë‹´ì‹¤ì‹œì¼'].dt.to_period('M').astype(str)
    df_diagnosis['ì§„ë‹¨ì—°ì›”'] = df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'].dt.to_period('M').astype(str)
    df_counseling['ì—°ë ¹ëŒ€'] = (df_counseling['ì‹ ì²­ì§ì›ë‚˜ì´'] // 10 * 10).astype('Int64').astype(str) + 'ëŒ€'
    df_counseling['ì„±ë³„'] = df_counseling['ì‹ ì²­ì§ì›ì„±ë³„'].fillna('ë¯¸ìƒ')

    # ID í´ë¦¬ë‹ í•¨ìˆ˜
    def clean_id(val):
        if pd.isnull(val):
            return None
        val = str(val).strip().replace(' ', '').replace('\u3000', '').lower()
        if val.endswith('.0'):
            val = val[:-2]
        if not val or val in {'nan', 'none', '0', '0.0'}:
            return None
        return val

    counseling_ids = df_counseling['ì•„ì´ë””'].apply(clean_id)
    diagnosis_ids = df_diagnosis['ì•„ì´ë””'].apply(clean_id)
    combined_ids = pd.concat([counseling_ids, diagnosis_ids])
    unique_ids = combined_ids.dropna().drop_duplicates()
    ì‹¤ê³„_ì¸ì›ìˆ˜ = len(unique_ids)

    # ì—°ì›” ëª©ë¡ ë§Œë“¤ê¸°
    valid_months_counseling = df_counseling['ìƒë‹´ì‹¤ì‹œì¼'].dropna()
    valid_months_diagnosis = df_diagnosis['ì§„ë‹¨ì‹¤ì‹œì¼'].dropna()
    all_valid_months = pd.concat([valid_months_counseling, valid_months_diagnosis])
    if len(all_valid_months) > 0:
        min_month = all_valid_months.min().to_period('M')
        max_month = all_valid_months.max().to_period('M')
        all_months = pd.period_range(min_month, max_month, freq='M').astype(str).tolist()
    else:
        all_months = []

    # ---------------------- ë©”ë‰´ë³„ ê¸°ëŠ¥ êµ¬í˜„ ----------------------
    if menu == "ğŸ“Š ìš´ì˜ ìš”ì•½":
        st.header("ğŸ“Š ìš´ì˜ ìš”ì•½")
        summary = pd.DataFrame({'ì—°ì›”': all_months})
        summary['ì‹¬ë¦¬ìƒë‹´'] = summary['ì—°ì›”'].apply(lambda m: df_counseling[df_counseling['ìƒë‹´ì—°ì›”'] == m]['ì•„ì´ë””'].nunique())
        summary['ì‹¬ë¦¬ì§„ë‹¨'] = summary['ì—°ì›”'].apply(lambda m: df_diagnosis[df_diagnosis['ì§„ë‹¨ì—°ì›”'] == m]['ì•„ì´ë””'].nunique())
        summary['í•©ê³„'] = summary['ì‹¬ë¦¬ìƒë‹´'] + summary['ì‹¬ë¦¬ì§„ë‹¨']
        summary.loc[len(summary)] = ['ëˆ„ê³„', summary['ì‹¬ë¦¬ìƒë‹´'].sum(), summary['ì‹¬ë¦¬ì§„ë‹¨'].sum(), summary['í•©ê³„'].sum()]
        summary.loc[len(summary)] = ['ì‹¤ê³„', df_counseling['ì•„ì´ë””'].nunique(), df_diagnosis['ì•„ì´ë””'].nunique(), ì‹¤ê³„_ì¸ì›ìˆ˜]
        st.subheader("ì„œë¹„ìŠ¤ ì´ìš© ì¸ì›")
        st.dataframe(summary, use_container_width=True)

        summary_count = pd.DataFrame({'ì—°ì›”': all_months})
        summary_count['ì‹¬ë¦¬ìƒë‹´'] = summary_count['ì—°ì›”'].apply(lambda m: len(df_counseling[df_counseling['ìƒë‹´ì—°ì›”'] == m]))
        summary_count['ì‹¬ë¦¬ì§„ë‹¨'] = summary_count['ì—°ì›”'].apply(lambda m: len(df_diagnosis[df_diagnosis['ì§„ë‹¨ì—°ì›”'] == m]))
        summary_count['í•©ê³„'] = summary_count['ì‹¬ë¦¬ìƒë‹´'] + summary_count['ì‹¬ë¦¬ì§„ë‹¨']
        summary_count.loc[len(summary_count)] = ['ëˆ„ê³„', summary_count['ì‹¬ë¦¬ìƒë‹´'].sum(), summary_count['ì‹¬ë¦¬ì§„ë‹¨'].sum(), summary_count['í•©ê³„'].sum()]
        st.subheader("ì„œë¹„ìŠ¤ ì´ìš© íšŸìˆ˜")
        st.dataframe(summary_count, use_container_width=True)

    elif menu == "ğŸ“ˆ ìƒë‹´ í†µê³„":
        st.header("ğŸ“ˆ ìƒë‹´ í†µê³„")
        # ìƒë‹´ìœ í˜•ë³„ ì¸ì› ë° íšŸìˆ˜
        type_people = df_counseling.groupby(['ìƒë‹´ì—°ì›”', 'ìƒë‹´ìœ í˜•'])['ì•„ì´ë””'].nunique().reset_index()
        type_people_summary = type_people.pivot(index='ìƒë‹´ì—°ì›”', columns='ìƒë‹´ìœ í˜•', values='ì•„ì´ë””')
        type_people_summary = type_people_summary.reindex(all_months).fillna(0).astype(int)
        type_people_summary['í•©ê³„'] = type_people_summary.sum(axis=1)
        type_people_summary.loc['ëˆ„ê³„'] = type_people_summary.sum()
        st.markdown("ìƒë‹´ìœ í˜•ë³„ ì´ìš© ì¸ì›")
        st.dataframe(type_people_summary)

        type_counts = df_counseling.groupby(['ìƒë‹´ì—°ì›”', 'ìƒë‹´ìœ í˜•'])['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
        type_counts_summary = type_counts.pivot(index='ìƒë‹´ì—°ì›”', columns='ìƒë‹´ìœ í˜•', values='ì‚¬ë¡€ë²ˆí˜¸')
        type_counts_summary = type_counts_summary.reindex(all_months).fillna(0).astype(int)
        type_counts_summary['í•©ê³„'] = type_counts_summary.sum(axis=1)
        type_counts_summary.loc['ëˆ„ê³„'] = type_counts_summary.sum()
        st.markdown("ìƒë‹´ìœ í˜•ë³„ ì´ìš© íšŸìˆ˜")
        st.dataframe(type_counts_summary)

        # ì„±ë³„ ì¸ì› ë° íšŸìˆ˜
        st.markdown("---")
        st.subheader("2) ì„±ë³„ ì´ìš© ì¸ì› ë° íšŸìˆ˜")
        gender_people = df_counseling.groupby(['ìƒë‹´ì—°ì›”', 'ì„±ë³„'])['ì•„ì´ë””'].nunique().reset_index()
        gender_people_summary = gender_people.pivot(index='ìƒë‹´ì—°ì›”', columns='ì„±ë³„', values='ì•„ì´ë””')
        gender_people_summary = gender_people_summary.reindex(all_months).fillna(0).astype(int)
        gender_people_summary['í•©ê³„'] = gender_people_summary.sum(axis=1)
        gender_people_summary.loc['ëˆ„ê³„'] = gender_people_summary.sum()
        st.dataframe(gender_people_summary)

        gender_counts = df_counseling.groupby(['ìƒë‹´ì—°ì›”', 'ì„±ë³„'])['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
        gender_counts_summary = gender_counts.pivot(index='ìƒë‹´ì—°ì›”', columns='ì„±ë³„', values='ì‚¬ë¡€ë²ˆí˜¸')
        gender_counts_summary = gender_counts_summary.reindex(all_months).fillna(0).astype(int)
        gender_counts_summary['í•©ê³„'] = gender_counts_summary.sum(axis=1)
        gender_counts_summary.loc['ëˆ„ê³„'] = gender_counts_summary.sum()
        st.dataframe(gender_counts_summary)

        # ì—°ë ¹ë³„ ì¸ì› ë° íšŸìˆ˜
        st.markdown("---")
        st.subheader("3) ì—°ë ¹ë³„ ì¸ì› ë° íšŸìˆ˜")
        age_monthly = df_counseling.groupby(['ìƒë‹´ì—°ì›”', 'ì—°ë ¹ëŒ€']).agg(
            ì¸ì›ìˆ˜=('ì•„ì´ë””', 'nunique'),
            ê±´ìˆ˜=('ì‚¬ë¡€ë²ˆí˜¸', 'count')
        ).reset_index()
        age_pivot_people = age_monthly.pivot(index='ìƒë‹´ì—°ì›”', columns='ì—°ë ¹ëŒ€', values='ì¸ì›ìˆ˜')
        age_pivot_people = age_pivot_people.reindex(all_months).fillna(0).astype(int)
        age_pivot_people['í•©ê³„'] = age_pivot_people.sum(axis=1)
        age_pivot_people.loc['ëˆ„ê³„'] = age_pivot_people.sum()
        st.dataframe(age_pivot_people)

        age_pivot_cases = age_monthly.pivot(index='ìƒë‹´ì—°ì›”', columns='ì—°ë ¹ëŒ€', values='ê±´ìˆ˜')
        age_pivot_cases = age_pivot_cases.reindex(all_months).fillna(0).astype(int)
        age_pivot_cases['í•©ê³„'] = age_pivot_cases.sum(axis=1)
        age_pivot_cases.loc['ëˆ„ê³„'] = age_pivot_cases.sum()
        st.dataframe(age_pivot_cases)

    elif menu == "ğŸ§  ì‹¬ë¦¬ì§„ë‹¨ í†µê³„":
        st.header("ğŸ§  ì‹¬ë¦¬ì§„ë‹¨ í†µê³„")
        diag_people = df_diagnosis.groupby(['ì§„ë‹¨ì—°ì›”', 'ì§„ë‹¨ëª…'])['ì•„ì´ë””'].nunique().reset_index()
        diag_people_summary = diag_people.pivot(index='ì§„ë‹¨ì—°ì›”', columns='ì§„ë‹¨ëª…', values='ì•„ì´ë””').fillna(0).astype(int)
        diag_people_summary['í•©ê³„'] = diag_people_summary.sum(axis=1)
        diag_people_summary.loc['ëˆ„ê³„'] = diag_people_summary.sum()
        st.markdown("ì‹¬ë¦¬ì§„ë‹¨ ì´ìš© ì¸ì›")
        st.dataframe(diag_people_summary)

        diag_counts = df_diagnosis.groupby(['ì§„ë‹¨ì—°ì›”', 'ì§„ë‹¨ëª…'])['ì‹œí–‰ë²ˆí˜¸'].count().reset_index()
        diag_counts_summary = diag_counts.pivot(index='ì§„ë‹¨ì—°ì›”', columns='ì§„ë‹¨ëª…', values='ì‹œí–‰ë²ˆí˜¸').fillna(0).astype(int)
        diag_counts_summary['í•©ê³„'] = diag_counts_summary.sum(axis=1)
        diag_counts_summary.loc['ëˆ„ê³„'] = diag_counts_summary.sum()
        st.markdown("ì‹¬ë¦¬ì§„ë‹¨ ì´ìš© íšŸìˆ˜")
        st.dataframe(diag_counts_summary)

    st.markdown("---")
    # ëŒ€ë¶„ë¥˜ ë§¤í•‘
    combined_mapping_dict = {
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ìƒì‚¬ì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ë¶€í•˜ì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'ë™ë£Œì™€ì˜ ê°ˆë“±'): 'ì§ì¥',
        ('ì§ì¥ ë‚´ ëŒ€ì¸ê´€ê³„', 'íŒ€ì›Œí¬ ë° ì‚¬ê¸° ì €í•˜'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì´ì§ê³ ë¯¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¡°ì§ë¬¸í™” ë¶€ì ì‘'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì—…ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¼í•  ì˜ìš•ì˜ ìƒì‹¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§ë¬´ì¬ë°°ì¹˜(TM,ì „ê·¼,ì´ì§)'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ìŠ¹ì§„ë¬¸ì œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'êµëŒ€ê·¼ë¬´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì—´ì•…í•œ ê·¼ë¬´ì¡°ê±´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§•ê³„/ê°ë´‰/ì§ìœ„í•´ì œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ë³´ìˆ˜ì— ë¶ˆë§Œ'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì‚°ì¬ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì”ì—…/íŠ¹ê·¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¶œí‡´ê·¼ ê´€ë ¨'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì ì„±ì— ë§ì§€ ì•ŠëŠ” ì—…ë¬´'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì„±ì°¨ë³„'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì„±í¬ë¡±'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ê°ì •ë…¸ë™'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'ì¦ì€ ì•¼ê·¼'): 'ì§ì¥',
        ('ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤', 'íœ´ì§í›„ ë³µê·€'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ë¦¬ë”ì‹­'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹œê°„ê´€ë¦¬'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì§„ë¡œ ë° ê²½ë ¥ê³„ë°œ'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹¤ì§ or ì •ë¦¬í•´ê³  ìŠ¤íŠ¸ë ˆìŠ¤'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì‹¤ì ì••ë°•'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'ì •ë…„í‡´ì§'): 'ì§ì¥',
        ('ì—­ëŸ‰ ë° ê²½ë ¥', 'í‡´ì§ í›„ ì¸ìƒì„¤ê³„'): 'ì§ì¥',
        ('í•™êµìƒí™œ', 'ì „ê³µ/ì§„ë¡œ ë¬¸ì œ'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'í•™ì—…/í•™ìŠµ ë¬¸ì œ'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'íœ´í•™ ë° ë³µí•™'): 'í•™êµ',
        ('í•™êµìƒí™œ', 'ê²½ì œì  ë¬¸ì œ (í•™ìê¸ˆ)'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'êµìˆ˜ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'ì¹œêµ¬ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        ('í•™êµ ë‚´ ëŒ€ì¸ê´€ê³„', 'ì„ í›„ë°°ì™€ì˜ ê´€ê³„'): 'í•™êµ',
        ('ë¶€ë¶€', 'ë¶€ë¶€ê°ˆë“±'): 'ê°€ì¡±',
        ('ë¶€ë¶€', 'ì´í˜¼ê³ ë¯¼'): 'ê°€ì¡±',
        ('ë¶€ë¶€', 'ì‚¬ë³„'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì¡±ê°ˆë“±(ë¶€ëª¨, í˜•ì œ ë“±)'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê³ ë¶€/ì²˜ê°€ ê°ˆë“±'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ë…¸ë¶€ëª¨ ë´‰ì–‘'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì •í­ë ¥'): 'ê°€ì¡±',
        ('ê°€ì¡±', 'ê°€ì¡±ì‚¬ë§(ë¶€ëª¨, í˜•ì œ ë“±)'): 'ê°€ì¡±',
        ('ìë…€', 'ê°€ì¡±ëŒë´„(ì¥ì• ë³´í˜¸, ìš”ì–‘ë³´í˜¸)'): 'ê°€ì¡±',
        ('ìë…€', 'ìë…€ì–‘ìœ¡/êµìœ¡'): 'ê°€ì¡±',
        ('ìë…€', 'ìë…€ ì •ì„œë¬¸ì œ(ìš°ìš¸, ë¶ˆì•ˆ, ADHD)'): 'ê°€ì¡±',
        ('ìë…€', 'ë°œë‹¬ì§€ì—°'): 'ê°€ì¡±',
        ('ìë…€', 'ì¥ì• ìë…€ ëŒë´„'): 'ê°€ì¡±',
        ('ì¼ë°˜', 'ëŒ€ì¸ê´€ê³„'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì‚¶ì˜ ì˜ë¯¸ì™€ ëª©í‘œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì„±ê²©ê³ ë¯¼'): 'ê°œì¸',
        ('ì¼ë°˜', 'ìê¸°ê³„ë°œ ë° ì„±ì¥'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì´ì„±êµì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì„±ìƒí™œë¬¸ì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ê±´ê°• ë° ì§ˆë³‘ ê´€ë ¨ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì½”ë¡œë…¸ ê´€ë ¨ ìŠ¤íŠ¸ë ˆìŠ¤'): 'ê°œì¸',
        ('ì¼ë°˜', 'ì¢…êµì /ì˜ì  ë¬¸ì œ'): 'ê°œì¸',
        ('ì¼ë°˜', 'ë¹„ë§Œ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì •ì„œì†Œì§„(ë²ˆì•„ì›ƒ)'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ìš°ìš¸ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¶ˆì•ˆ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê³µí™©ì¥ì• '): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¶ˆë©´ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê°•ë°•'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì§œì¦/ë¶„ë…¸'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ê°ì •ê¸°ë³µ'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì¡°ìš¸ì¦'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'í™˜ê°/í™˜ì²­'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'PTSD'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ìí•´'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ë¬´ê¸°ë ¥'): 'ê°œì¸',
        ('ì •ì‹ ê±´ê°•', 'ì‚°í›„ìš°ìš¸'): 'ê°œì¸',
        ('ì¤‘ë…', 'ì¸í„°ë„·/ê²Œì„/ìŠ¤ë§ˆíŠ¸í°'): 'ê°œì¸',
        ('ì¤‘ë…', 'ì•Œì½”ì˜¬'): 'ê°œì¸',
        ('ì¤‘ë…', 'ë„ë°•'): 'ê°œì¸',
        ('ì¤‘ë…', 'í¡ì—°'): 'ê°œì¸',
        ('ìì‚´ìœ„ê¸°', 'ìì‚´ìƒê°'): 'ê°œì¸',
        ('ìì‚´ìœ„ê¸°', 'ìì‚´ê³„íš'): 'ê°œì¸',
        ('ìì‚´ìœ„ê¸°', 'ìì‚´ì‹œë„ê²½í—˜'): 'ê°œì¸',
        ('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ë²•ë¥ ìƒë‹´(ë³€í˜¸ì‚¬)'): 'ê°œì¸',
        ('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'íšŒê³„ìƒë‹´(íšŒê³„ì‚¬)'): 'ê°œì¸',
        ('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ì¬ë¬´ìƒë‹´(ì¬ë¬´ì„¤ê³„ì‚¬)'): 'ê°œì¸',
        ('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ì„¸ë¬´ìƒë‹´(ì„¸ë¬´ì‚¬)'): 'ê°œì¸',
        ('ì¬ì • ë° ë²•ë¥ ìë¬¸ ë“±', 'ê±´ê°•ìƒë‹´'): 'ê°œì¸',
    }

    def clean_str(s):
        if pd.isnull(s):
            return ""
        return str(s).strip().replace(" ", "").lower()

    combined_mapping_dict_clean = {
        (clean_str(k1), clean_str(k2)): v
        for (k1, k2), v in combined_mapping_dict.items()
    }

    def map_region(row):
        if clean_str(row['ì£¼í˜¸ì†Œ1']) == 'ê¸°íƒ€':
            return 'ê¸°íƒ€'
        return combined_mapping_dict_clean.get(
            (clean_str(row['ì£¼í˜¸ì†Œ1']), clean_str(row['í•˜ìœ„ìš”ì†Œ1'])), None
        )

    df_counseling['ì˜ì—­'] = df_counseling.apply(map_region, axis=1)

    count_df = (
        df_counseling
        .groupby(['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1'])
        .size().reset_index(name='ìƒë‹´ê±´ìˆ˜')
        .sort_values(['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1'])
        .reset_index(drop=True)
    )

    st.header("ìƒë‹´ ì£¼ì œë³„ í†µê³„")
    st.markdown("1) ê°œìš”")
    st.dataframe(count_df)

    not_mapped = df_counseling[df_counseling['ì˜ì—­'].isnull()]
    not_mapped = not_mapped[~(not_mapped['ì£¼í˜¸ì†Œ1'].isnull() & not_mapped['í•˜ìœ„ìš”ì†Œ1'].isnull())]
    st.write(f"ë§¤í•‘ì´ ì•ˆ ëœ ìƒë‹´(ë¯¸ë¶„ë¥˜) ê±´ìˆ˜: {len(not_mapped)}")
    if len(not_mapped) > 0:
        st.write("ë¯¸ë¶„ë¥˜ ê±´(ì£¼í˜¸ì†Œ1, í•˜ìœ„ìš”ì†Œ1) ëª©ë¡ (ì¤‘ë³µì œê±°):")
        st.dataframe(not_mapped[['ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1']].drop_duplicates())

    area_sum_df = (
        count_df.groupby('ì˜ì—­')['ìƒë‹´ê±´ìˆ˜'].sum().reset_index()
        .sort_values('ìƒë‹´ê±´ìˆ˜', ascending=False)
    )
    area_sum_df.columns = ['ì˜ì—­', 'ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„']
    total_row = pd.DataFrame({
        'ì˜ì—­': ['í•©ê³„'],
        'ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„': [area_sum_df['ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„'].sum()]
    })
    area_sum_df_with_total = pd.concat([area_sum_df, total_row], ignore_index=True)
    st.markdown("2) ì˜ì—­ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„")
    st.dataframe(area_sum_df_with_total)

    main_issue_sum_df = (
    count_df
    .groupby(['ì˜ì—­','ì£¼í˜¸ì†Œ1'])['ìƒë‹´ê±´ìˆ˜'].sum()
    .reset_index()
    .sort_values('ìƒë‹´ê±´ìˆ˜', ascending=False)
    )
    main_issue_sum_df.columns = ['ì˜ì—­', 'ì£¼í˜¸ì†Œ1', 'ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„']

    # í•©ê³„ í–‰ ì¶”ê°€
    total_row = pd.DataFrame([{
        'ì˜ì—­': 'í•©ê³„',
        'ì£¼í˜¸ì†Œ1': '',
        'ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„': main_issue_sum_df['ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„'].sum()
    }])
    main_issue_sum_df_with_total = pd.concat([main_issue_sum_df, total_row], ignore_index=True)

    st.markdown("3) ì£¼í˜¸ì†Œ1ë³„ ìƒë‹´ê±´ìˆ˜ í•©ê³„")
    st.dataframe(main_issue_sum_df_with_total)

    missing_count = df_counseling['ì£¼í˜¸ì†Œ1'].isnull().sum()
    if missing_count > 0:
        st.warning(f"'ì£¼í˜¸ì†Œ1' ì—´ì— ê²°ì¸¡ì¹˜ê°€ {missing_count}ê±´ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ í–‰ì€ ë¶„ì„ì—ì„œ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        with st.expander("'ì£¼í˜¸ì†Œ1' ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ìƒë‹´ ë‚´ì—­ ë³´ê¸°"):
            st.dataframe(df_counseling[df_counseling['ì£¼í˜¸ì†Œ1'].isnull()][['ì‚¬ë¡€ë²ˆí˜¸', 'ì•„ì´ë””', 'ìƒë‹´ì‹¤ì‹œì¼', 'ì£¼í˜¸ì†Œ1', 'í•˜ìœ„ìš”ì†Œ1']])
    else:
        st.info("'ì£¼í˜¸ì†Œ1' ì—´ì— ê²°ì¸¡ì¹˜ëŠ” ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.header("ë‚´ë‹´ìë³„ ì „ì²´ ìƒë‹´ ì´ìš© íšŸìˆ˜")
    client_counts = df_counseling.groupby('ì•„ì´ë””')['ì‚¬ë¡€ë²ˆí˜¸'].count().reset_index()
    client_counts.columns = ['ì•„ì´ë””', 'ìƒë‹´íšŸìˆ˜']
    client_counts['ì•„ì´ë””'] = client_counts['ì•„ì´ë””'].apply(lambda x: str(int(float(x))) if pd.notnull(x) and str(x).replace('.', '', 1).isdigit() else str(x))
    client_counts.index = client_counts.index + 1
    client_counts.reset_index(inplace=True)
    client_counts.rename(columns={'index': 'No'}, inplace=True)

    total_row = pd.DataFrame([{
        'No': 'í•©ê³„',
        'ì•„ì´ë””': f"ì´ {client_counts['ì•„ì´ë””'].nunique()}ëª…",
        'ìƒë‹´íšŸìˆ˜': client_counts['ìƒë‹´íšŸìˆ˜'].sum()
    }])
    client_counts_with_total = pd.concat([client_counts, total_row], ignore_index=True)
    st.dataframe(client_counts_with_total, use_container_width=True)